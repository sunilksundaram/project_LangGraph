{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d616f94-b959-4815-8e12-76006da1f77c",
   "metadata": {},
   "source": [
    "# Tech Product Evaluation System using LangGraph for Quantitative Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ca7c30-e527-4ca6-9779-af3479bbb1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, TypedDict, Annotated\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fad7b34-f675-4aeb-8dda-ba538e58a880",
   "metadata": {},
   "source": [
    "## Define the State Schema for ProductAnalysis & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85538fb2-564d-4885-bc38-76d9e3c625c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state schema\n",
    "class ProductAnalysis(TypedDict):\n",
    "    product: str\n",
    "    evaluation: Dict[str, Dict[str, Any]]\n",
    "\n",
    "class ComparisonState(TypedDict):\n",
    "    products: List[str]\n",
    "    criteria: List[str]\n",
    "    weights: Dict[str, float]\n",
    "    analysis: List[ProductAnalysis]\n",
    "    scores: Dict[str, Any]\n",
    "    current_product_index: int\n",
    "    status: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb98bbfe-ca55-4072-8b7d-a37b1270ceff",
   "metadata": {},
   "source": [
    "## Initialize the OpenAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d5577c1-0873-4364-9c25-103b9bad911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0, top_p=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e74e2b7-ccee-4149-bc74-ac17c52dbc20",
   "metadata": {},
   "source": [
    "## Create the Nodes\n",
    "### Analyze Product Node to fetch reviews from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb72e67-7adc-4fb4-90e0-c6a6b87f147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_product(state: ComparisonState) -> ComparisonState:\n",
    "    products = state[\"products\"]\n",
    "    criteria = state[\"criteria\"]\n",
    "    weights = state[\"weights\"]\n",
    "    current_idx = state[\"current_product_index\"]\n",
    "    \n",
    "    if current_idx >= len(products):\n",
    "        state[\"status\"] = \"scoring\"\n",
    "        return state\n",
    "    \n",
    "    current_product = products[current_idx]\n",
    "    \n",
    "    analysis_prompt = f\"\"\"\n",
    "    Analyze the following tech product: {current_product}\n",
    "    Based on these criteria (with weights): {json.dumps(weights)}\n",
    "    \n",
    "    For each criterion:\n",
    "    1. Provide detailed analysis\n",
    "    2. Assign a score from 0-10\n",
    "    3. Provide a confidence score (0-10) for your assessment based on:\n",
    "       - Data availability\n",
    "       - Market consensus\n",
    "       - Technical specifications clarity\n",
    "       - Your knowledge of the product category\n",
    "    \n",
    "    Format your response as JSON with this structure:\n",
    "    {{\n",
    "        \"analysis\": {{\n",
    "            \"criterion\": {{\n",
    "                \"details\": \"analysis text\",\n",
    "                \"score\": numeric_score,\n",
    "                \"confidence\": numeric_confidence_score,\n",
    "                \"confidence_reasoning\": \"explanation of confidence score\"\n",
    "            }}\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=analysis_prompt)])\n",
    "    analysis_result = json.loads(response.content)\n",
    "    \n",
    "    state[\"analysis\"].append({\n",
    "        \"product\": current_product,\n",
    "        \"evaluation\": analysis_result[\"analysis\"]\n",
    "    })\n",
    "    \n",
    "    state[\"current_product_index\"] += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb8bc9f-4c71-475d-a6e9-e6e88c01d08e",
   "metadata": {},
   "source": [
    "### Calculate the Weighted Average Score from the LLM output along with Confidence Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10dae2f6-5f97-4f01-8d39-bbfc1ace294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_scores(state: ComparisonState) -> ComparisonState:\n",
    "    scores = {}\n",
    "    weights = state[\"weights\"]\n",
    "    total_weight = sum(weights.values())\n",
    "    \n",
    "    for analysis in state[\"analysis\"]:\n",
    "        product = analysis[\"product\"]\n",
    "        weighted_score = 0\n",
    "        criterion_scores = {}\n",
    "        confidence_scores = {}\n",
    "        detailed_calculations = {}\n",
    "        \n",
    "        for criterion, details in analysis[\"evaluation\"].items():\n",
    "            criterion_weight = weights[criterion] / total_weight\n",
    "            raw_score = details[\"score\"]\n",
    "            confidence = details[\"confidence\"]\n",
    "            \n",
    "            criterion_scores[criterion] = raw_score\n",
    "            confidence_scores[criterion] = confidence\n",
    "            \n",
    "            confidence_factor = confidence / 10\n",
    "            adjusted_weight = criterion_weight * confidence_factor\n",
    "            weighted_criterion_score = raw_score * adjusted_weight\n",
    "            \n",
    "            detailed_calculations[criterion] = {\n",
    "                \"raw_score\": raw_score,\n",
    "                \"weight\": criterion_weight,\n",
    "                \"confidence\": confidence,\n",
    "                \"confidence_reasoning\": details[\"confidence_reasoning\"],\n",
    "                \"weighted_score\": round(weighted_criterion_score, 2)\n",
    "            }\n",
    "            \n",
    "            weighted_score += weighted_criterion_score\n",
    "        \n",
    "        normalized_score = weighted_score * (10 / total_weight)\n",
    "        \n",
    "        scores[product] = {\n",
    "            \"overall_score\": round(normalized_score, 2),\n",
    "            \"raw_criterion_scores\": criterion_scores,\n",
    "            \"confidence_scores\": confidence_scores,\n",
    "            \"detailed_calculations\": detailed_calculations,\n",
    "            \"average_confidence\": round(sum(confidence_scores.values()) / len(confidence_scores), 2)\n",
    "        }\n",
    "    \n",
    "    state[\"scores\"] = scores\n",
    "    state[\"status\"] = \"complete\"\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f62c4f-7ca9-4673-8562-7984ea047f0b",
   "metadata": {},
   "source": [
    "## Router to handle multiple Products and Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05ff6e36-9c49-41df-b1eb-3b7487a6b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state: ComparisonState) -> str:\n",
    "    if state[\"status\"] == \"scoring\":\n",
    "        return \"calculate_scores\"\n",
    "    elif state[\"status\"] == \"complete\":\n",
    "        return END\n",
    "    else:\n",
    "        return \"analyze_product\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f9df32-e699-489f-bc98-dfac4f7c7aba",
   "metadata": {},
   "source": [
    "## Build the Graph to allow moving through various Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ac6e89e-2774-4663-81a0-12bd8f702524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_graph() -> StateGraph:\n",
    "    # Define the graph with state schema\n",
    "    workflow = StateGraph(ComparisonState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"analyze_product\", analyze_product)\n",
    "    workflow.add_node(\"calculate_scores\", calculate_weighted_scores)\n",
    "    \n",
    "    # Add conditional edges using the router\n",
    "    workflow.add_conditional_edges(\n",
    "        \"analyze_product\",\n",
    "        router,\n",
    "        {\n",
    "            \"analyze_product\": \"analyze_product\",\n",
    "            \"calculate_scores\": \"calculate_scores\",\n",
    "            END: END\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    workflow.add_conditional_edges(\n",
    "        \"calculate_scores\",\n",
    "        router,\n",
    "        {\n",
    "            \"analyze_product\": \"analyze_product\",\n",
    "            \"calculate_scores\": \"calculate_scores\",\n",
    "            END: END\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"analyze_product\")\n",
    "    \n",
    "    return workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f437ed4-4e6f-454f-8843-b1c6d775184f",
   "metadata": {},
   "source": [
    "## Putting it all together - Comparing the tech Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d307f0d-4c34-466f-9445-9e09a1a6faf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_tech_products(\n",
    "    products: List[str], criteria_weights: Dict[str, float]) -> Dict[str, Any]:\n",
    "    # Initialize state with proper typing\n",
    "    initial_state: ComparisonState = {\n",
    "        \"products\": products,\n",
    "        \"criteria\": list(criteria_weights.keys()),\n",
    "        \"weights\": criteria_weights,\n",
    "        \"analysis\": [],\n",
    "        \"scores\": {},\n",
    "        \"current_product_index\": 0,\n",
    "        \"status\": \"initializing\"\n",
    "    }\n",
    "    \n",
    "    graph = create_comparison_graph()\n",
    "    graph_app = graph.compile()\n",
    "    # graph_app.validate()\n",
    "    \n",
    "    final_state = graph_app.invoke(initial_state)\n",
    "    \n",
    "    return final_state[\"scores\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75064fff-f097-4000-aa1d-f23be2ad18e6",
   "metadata": {},
   "source": [
    "## Initiate the run & Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66d2c6dd-293d-4866-9fcd-92b27bc580e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"MacBook Pro M2\": {\n",
      "    \"overall_score\": 65.2,\n",
      "    \"raw_criterion_scores\": {\n",
      "      \"Performance\": 9,\n",
      "      \"Battery Life\": 8,\n",
      "      \"Build Quality\": 9,\n",
      "      \"Value for Money\": 7\n",
      "    },\n",
      "    \"confidence_scores\": {\n",
      "      \"Performance\": 8,\n",
      "      \"Battery Life\": 7,\n",
      "      \"Build Quality\": 9,\n",
      "      \"Value for Money\": 7\n",
      "    },\n",
      "    \"detailed_calculations\": {\n",
      "      \"Performance\": {\n",
      "        \"raw_score\": 9,\n",
      "        \"weight\": 0.35,\n",
      "        \"confidence\": 8,\n",
      "        \"confidence_reasoning\": \"While the exact specifications of the M2 chip are not yet known, the performance of the M1 chip and Apple's track record of improving performance with each new chip generation provide a strong basis for this assessment.\",\n",
      "        \"weighted_score\": 2.52\n",
      "      },\n",
      "      \"Battery Life\": {\n",
      "        \"raw_score\": 8,\n",
      "        \"weight\": 0.25,\n",
      "        \"confidence\": 7,\n",
      "        \"confidence_reasoning\": \"While the exact battery life of the M2 MacBook Pro is not yet known, the battery life of the M1 MacBook Pro and the power efficiency of Apple's M-series chips provide a strong basis for this assessment.\",\n",
      "        \"weighted_score\": 1.4\n",
      "      },\n",
      "      \"Build Quality\": {\n",
      "        \"raw_score\": 9,\n",
      "        \"weight\": 0.2,\n",
      "        \"confidence\": 9,\n",
      "        \"confidence_reasoning\": \"Apple's track record of high build quality in its MacBook Pro line provides a strong basis for this assessment.\",\n",
      "        \"weighted_score\": 1.62\n",
      "      },\n",
      "      \"Value for Money\": {\n",
      "        \"raw_score\": 7,\n",
      "        \"weight\": 0.2,\n",
      "        \"confidence\": 7,\n",
      "        \"confidence_reasoning\": \"While the exact price of the M2 MacBook Pro is not yet known, the price of the M1 MacBook Pro and Apple's pricing trends provide a basis for this assessment.\",\n",
      "        \"weighted_score\": 0.98\n",
      "      }\n",
      "    },\n",
      "    \"average_confidence\": 7.75\n",
      "  },\n",
      "  \"Dell XPS 13\": {\n",
      "    \"overall_score\": 68.2,\n",
      "    \"raw_criterion_scores\": {\n",
      "      \"Performance\": 9,\n",
      "      \"Battery Life\": 8,\n",
      "      \"Build Quality\": 9,\n",
      "      \"Value for Money\": 8\n",
      "    },\n",
      "    \"confidence_scores\": {\n",
      "      \"Performance\": 8,\n",
      "      \"Battery Life\": 7,\n",
      "      \"Build Quality\": 9,\n",
      "      \"Value for Money\": 8\n",
      "    },\n",
      "    \"detailed_calculations\": {\n",
      "      \"Performance\": {\n",
      "        \"raw_score\": 9,\n",
      "        \"weight\": 0.35,\n",
      "        \"confidence\": 8,\n",
      "        \"confidence_reasoning\": \"The performance assessment is based on the technical specifications provided by Dell and reviews from users and experts. However, performance can vary depending on the specific configuration of the laptop and the software being used.\",\n",
      "        \"weighted_score\": 2.52\n",
      "      },\n",
      "      \"Battery Life\": {\n",
      "        \"raw_score\": 8,\n",
      "        \"weight\": 0.25,\n",
      "        \"confidence\": 7,\n",
      "        \"confidence_reasoning\": \"The battery life assessment is based on Dell's claims and reviews from users and experts. However, battery life can vary greatly depending on the specific usage patterns and settings.\",\n",
      "        \"weighted_score\": 1.4\n",
      "      },\n",
      "      \"Build Quality\": {\n",
      "        \"raw_score\": 9,\n",
      "        \"weight\": 0.2,\n",
      "        \"confidence\": 9,\n",
      "        \"confidence_reasoning\": \"The build quality assessment is based on the materials used in the construction of the laptop, as well as reviews from users and experts. The Dell XPS 13 has a reputation for being well-built and durable.\",\n",
      "        \"weighted_score\": 1.62\n",
      "      },\n",
      "      \"Value for Money\": {\n",
      "        \"raw_score\": 8,\n",
      "        \"weight\": 0.2,\n",
      "        \"confidence\": 8,\n",
      "        \"confidence_reasoning\": \"The value for money assessment is based on the price of the laptop compared to its features and performance. While the Dell XPS 13 is expensive, it offers a lot of value for its price.\",\n",
      "        \"weighted_score\": 1.28\n",
      "      }\n",
      "    },\n",
      "    \"average_confidence\": 8.0\n",
      "  },\n",
      "  \"Lenovo ThinkPad X1 Carbon\": {\n",
      "    \"overall_score\": 68.6,\n",
      "    \"raw_criterion_scores\": {\n",
      "      \"Performance\": 9,\n",
      "      \"Battery Life\": 8,\n",
      "      \"Build Quality\": 9,\n",
      "      \"Value for Money\": 7\n",
      "    },\n",
      "    \"confidence_scores\": {\n",
      "      \"Performance\": 8,\n",
      "      \"Battery Life\": 8,\n",
      "      \"Build Quality\": 9,\n",
      "      \"Value for Money\": 8\n",
      "    },\n",
      "    \"detailed_calculations\": {\n",
      "      \"Performance\": {\n",
      "        \"raw_score\": 9,\n",
      "        \"weight\": 0.35,\n",
      "        \"confidence\": 8,\n",
      "        \"confidence_reasoning\": \"The performance assessment is based on the laptop's technical specifications and market reviews. However, actual performance may vary depending on the specific tasks and software used.\",\n",
      "        \"weighted_score\": 2.52\n",
      "      },\n",
      "      \"Battery Life\": {\n",
      "        \"raw_score\": 8,\n",
      "        \"weight\": 0.25,\n",
      "        \"confidence\": 8,\n",
      "        \"confidence_reasoning\": \"The battery life assessment is based on manufacturer claims and market reviews. Actual battery life may vary depending on usage patterns and settings.\",\n",
      "        \"weighted_score\": 1.6\n",
      "      },\n",
      "      \"Build Quality\": {\n",
      "        \"raw_score\": 9,\n",
      "        \"weight\": 0.2,\n",
      "        \"confidence\": 9,\n",
      "        \"confidence_reasoning\": \"The build quality assessment is based on the laptop's materials, design, and manufacturer claims of durability.\",\n",
      "        \"weighted_score\": 1.62\n",
      "      },\n",
      "      \"Value for Money\": {\n",
      "        \"raw_score\": 7,\n",
      "        \"weight\": 0.2,\n",
      "        \"confidence\": 8,\n",
      "        \"confidence_reasoning\": \"The value for money assessment is based on the laptop's price, features, and comparison with other laptops in the same price range.\",\n",
      "        \"weighted_score\": 1.12\n",
      "      }\n",
      "    },\n",
      "    \"average_confidence\": 8.25\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    products = [\n",
    "        \"MacBook Pro M2\",\n",
    "        \"Dell XPS 13\",\n",
    "        \"Lenovo ThinkPad X1 Carbon\"\n",
    "    ]\n",
    "    \n",
    "    criteria_weights = {\n",
    "        \"Performance\": 0.35,\n",
    "        \"Battery Life\": 0.25,\n",
    "        \"Build Quality\": 0.20,\n",
    "        \"Value for Money\": 0.20\n",
    "    }\n",
    "    \n",
    "    results = compare_tech_products(products, criteria_weights)\n",
    "    print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b7684-aa6c-4db9-a4be-d766ac9a9d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
